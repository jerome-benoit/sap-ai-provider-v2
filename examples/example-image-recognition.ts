#!/usr/bin/env node

/**
 * SAP AI Provider - Image Recognition Example
 *
 * This example demonstrates multi-modal capabilities (text + images)
 * using the SAP AI Provider with vision-enabled models.
 *
 * Authentication:
 * - On SAP BTP: Automatically uses service binding (VCAP_SERVICES)
 * - Locally: Set AICORE_SERVICE_KEY environment variable with your service key JSON
 */

// Load environment variables
import "dotenv/config";
import { APICallError, LoadAPIKeyError, NoSuchModelError } from "@ai-sdk/provider";
import { generateText } from "ai";
// In YOUR production project, use the published package instead:
// import { createSAPAIProvider } from "@jerome-benoit/sap-ai-provider";
// ============================================================================

// ============================================================================
// NOTE: Import Path for Development vs Production
// ============================================================================
// This example uses relative imports for local development within this repo:
import { createSAPAIProvider } from "../src/index";

/**
 *
 */
async function imageRecognitionExample() {
  console.log("üñºÔ∏è  SAP AI Image Recognition Example\n");

  // Verify AICORE_SERVICE_KEY is set for local development
  if (!process.env.AICORE_SERVICE_KEY && !process.env.VCAP_SERVICES) {
    console.warn("‚ö†Ô∏è  Warning: AICORE_SERVICE_KEY environment variable not set.");
    console.warn("   Set it in your .env file or environment for local development.\n");
  }

  try {
    const provider = createSAPAIProvider();

    // Example 1: Using a public URL
    console.log("üì∏ Example 1: Public URL Image");
    console.log("==============================");

    const { text: urlResponse } = await generateText({
      messages: [
        {
          content: [
            {
              text: "What do you see in this image?",
              type: "text",
            },
            {
              image: new URL(
                "https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/PNG_transparency_demonstration_1.png/280px-PNG_transparency_demonstration_1.png",
              ),
              type: "image",
            },
          ],
          role: "user",
        },
      ],
      model: provider("gpt-4o"),
    });

    console.log("ü§ñ Response:", urlResponse);
    console.log("");

    // Example 2: Using base64 encoded image
    console.log("üì∏ Example 2: Base64 Encoded Image");
    console.log("==================================");

    // Small 1x1 pixel red PNG for demo
    const base64Image =
      "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mP8/5+hHgAHggJ/PchI7wAAAABJRU5ErkJggg==";

    const { text: base64Response } = await generateText({
      messages: [
        {
          content: [
            {
              text: "Describe this image in detail.",
              type: "text",
            },
            {
              image: `data:image/png;base64,${base64Image}`,
              type: "image",
            },
          ],
          role: "user",
        },
      ],
      model: provider("gpt-4o"),
    });

    console.log("ü§ñ Response:", base64Response);
    console.log("");

    // Example 3: Multiple images analysis
    console.log("üì∏ Example 3: Multiple Images Analysis");
    console.log("=====================================");

    const { text: multiResponse } = await generateText({
      messages: [
        {
          content: [
            {
              text: "Compare these two images and tell me what you notice:",
              type: "text",
            },
            {
              image: new URL(
                "https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/PNG_transparency_demonstration_1.png/280px-PNG_transparency_demonstration_1.png",
              ),
              type: "image",
            },
            {
              image: `data:image/png;base64,${base64Image}`,
              type: "image",
            },
          ],
          role: "user",
        },
      ],
      model: provider("gpt-4o"),
    });

    console.log("ü§ñ Response:", multiResponse);
    console.log("");

    console.log("‚úÖ All examples completed successfully!");
  } catch (error: unknown) {
    if (error instanceof LoadAPIKeyError) {
      console.error("‚ùå Authentication Error:", error.message);
    } else if (error instanceof NoSuchModelError) {
      console.error("‚ùå Model Not Found:", error.modelId);
    } else if (error instanceof APICallError) {
      console.error("‚ùå API Call Error:", error.statusCode, error.message);

      // Parse SAP-specific metadata
      const sapError = JSON.parse(error.responseBody ?? "{}") as {
        error?: { code?: string; request_id?: string };
      };
      if (sapError.error?.request_id) {
        console.error("   SAP Request ID:", sapError.error.request_id);
        console.error("   SAP Error Code:", sapError.error.code);
      }
    } else {
      const errorMessage = error instanceof Error ? error.message : String(error);
      console.error("‚ùå Example failed:", errorMessage);
    }

    console.error("\nüí° Troubleshooting tips:");
    console.error("   - Ensure AICORE_SERVICE_KEY is set with valid credentials");
    console.error("   - Check that your SAP AI Core instance is accessible");
    console.error("   - Verify the model is available in your deployment");
  }
}

imageRecognitionExample().catch(console.error);

export { imageRecognitionExample };
